{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danish\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as tq\n",
    "import nltk\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import log_loss,accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove = open(r'Z:\\DS DATA\\glove.6B.300d.txt',encoding=\"utf8\")\n",
    "\n",
    "# start_time =time.clock()\n",
    "# glovedict={}\n",
    "# for line in glove:\n",
    "#     l=line.split()\n",
    "#     glovedict[l[0]] =np.asarray(l[1:])\n",
    "# print(time.clock()-start_time,\"seconds\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 33)\n",
      "['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate', 'freq_qid1', 'freq_qid2', 'q1_total_words', 'q2_total_words', 'q1_n_words', 'q2_n_words', 'q1_union_q2', 'q1_q2_word_share', 'total_words', 'word_share', 'intr_by_union', 'fq1_pls_fq2', 'fq1_diff_fq2', 'cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'fw_com', 'lw_com', 'abs_diff', 'ratio', 'token_set_ratio', 'token_sort_ratio', 'fuzz_ratio', 'partial_ratio']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"Z:\\DS DATA\\feature_train.csv\")\n",
    "print(df.shape)\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404210, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1_total_words</th>\n",
       "      <th>q2_total_words</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>q1_union_q2</th>\n",
       "      <th>q1_q2_word_share</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>fw_com</th>\n",
       "      <th>lw_com</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>partial_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the story of kohinoor  koh-i-noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.384612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1  what is the story of kohinoor  koh-i-noor  dia...   \n",
       "\n",
       "                                           question2  freq_qid1  freq_qid2  \\\n",
       "0  what is the step by step guide to invest in sh...          1          1   \n",
       "1  what would happen if the indian government sto...          4          1   \n",
       "\n",
       "   q1_total_words  q2_total_words  q1_n_words  q2_n_words  q1_union_q2  \\\n",
       "0              14              12          12          11           13   \n",
       "1               8              13           8          12           16   \n",
       "\n",
       "   q1_q2_word_share  ...   ctc_min   ctc_max  fw_com  lw_com  abs_diff  ratio  \\\n",
       "0                10  ...  0.916659  0.785709     1.0     0.0       2.0   13.0   \n",
       "1                 4  ...  0.624992  0.384612     1.0     0.0       5.0   10.5   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  partial_ratio  \n",
       "0              100                93          93            100  \n",
       "1               86                63          66             75  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target = df[\"is_duplicate\"]\n",
    "df.dropna(axis=0,inplace=True)\n",
    "df.drop(columns=['id','qid1','qid2','is_duplicate'],axis=1,inplace=True)\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilizing TFIDF VECTORIZEER FOR QUESTION 1 AND QUESTION 2\n",
    "Tfidf_Vect_question1 = TfidfVectorizer()\n",
    "Tfidf_Vect_question2 = TfidfVectorizer()\n",
    "\n",
    "\n",
    "# Creating features of question\n",
    "Tfidf_q1 = Tfidf_Vect_question1.fit_transform(df[\"question1\"].values.astype(\"U\")) \n",
    "Tfidf_q2 = Tfidf_Vect_question2.fit_transform(df[\"question2\"].values.astype(\"U\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of features created from quesiton1 are:   62092\n",
      "Total no of features created from quesiton2 are:   57137\n"
     ]
    }
   ],
   "source": [
    "print(\"Total no of features created from quesiton1 are:  \",len(Tfidf_Vect_question1.get_feature_names()))\n",
    "print(\"Total no of features created from quesiton2 are:  \",len(Tfidf_Vect_question2.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# scipy.sparse.hstack(blocks, format=None, dtype=None)\n",
    "    # Stack sparse matrices horizontally (column wise)\n",
    "\n",
    "# Parameters\n",
    "    # blocks\n",
    "    # sequence of sparse matrices with compatible shapes\n",
    "\n",
    "# formatstr\n",
    "    # sparse format of the result (e.g., “csr”) by default an appropriate\n",
    "    # sparse matrix format is returned. This choice is subject to change.\n",
    "\n",
    "# dtypedtype, optional\n",
    "    # The data-type of the output matrix. If not given, the dtype is determined from that of\n",
    "\n",
    "\n",
    "# from scipy.sparse import hstack,coo_matrix\n",
    "# A=coo_matrix([[1,2],[3,5]])\n",
    "# B=coo_matrix([[0],[4]])\n",
    "# d=hstack([A,B]).toarray()\n",
    "# d\n",
    "# ----------------output--------------\n",
    "# array([[1, 2, 0],\n",
    "#        [3, 5, 4]], dtype=int32)\n",
    "question1_question2 = hstack((Tfidf_q1,Tfidf_q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['question1','question2'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404210, 119256)\n"
     ]
    }
   ],
   "source": [
    "df_features_tfidf_features = hstack((df,question1_question2),format=\"csr\",dtype=\"float64\")\n",
    "print(df_features_tfidf_features.get_shape()) # also shape can be used to and works same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    62746\n",
      "1    37254\n",
      "Name: is_duplicate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2=df[:][:100000]\n",
    "# docs = list(df2['question1']) + list(df2['question2']) \n",
    "print(df2[\"is_duplicate\"].value_counts())\n",
    "# print(\"percentage wise \",\n",
    "#       ((df2[\"is_duplicate\"].value_counts()[0])/len(df2[\"is_duplicate\"])*100),\"%\"\n",
    "#       \"\\t\",((df2[\"is_duplicate\"].value_counts()[1])/len(df2[\"is_duplicate\"])*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62746\n",
      "0.37254\n"
     ]
    }
   ],
   "source": [
    "print(((df2[\"is_duplicate\"].value_counts()[0])/len(df2[\"is_duplicate\"])))\n",
    "print(((df2[\"is_duplicate\"].value_counts()[1])/len(df2[\"is_duplicate\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.fillna(value=\" \",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "HEIGHEST_LEN = 0\n",
    "for i in range(len(df2['question1'])):\n",
    "        HEIGHEST_LEN=max(HEIGHEST_LEN,len(word_tokenize(df2['question1'][i])))\n",
    "        HEIGHEST_LEN=max(HEIGHEST_LEN,len(word_tokenize(df2['question2'][i])))\n",
    "#     print(len(word_tokenize(df2['question1'][i])),len(word_tokenize(df2['question2'][i])))    \n",
    "HEIGHEST_LEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df2['question1'].tolist() +df2['question2'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.370890000000003 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time =time.clock()\n",
    "tfidf = TfidfVectorizer()\n",
    "# countvect =CountVectorizer()\n",
    "tfidf.fit_transform(docs)\n",
    "tfidf_dict = dict(zip(tfidf.get_feature_names(),tfidf.idf_))\n",
    "print(time.clock()-start_time,\"seconds\")\n",
    "# len(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.9502947 seconds\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "start_time =time.clock()\n",
    "def get_question_tfidf(x):\n",
    "    x_np=np.zeros(HEIGHEST_LEN)    \n",
    "    q1=word_tokenize(x)\n",
    "    for i in range(len(q1)):\n",
    "        x_np[i] = tfidf_dict.get(q1[i],0)\n",
    "    return x_np\n",
    "q1_x = df2['question1'].apply(get_question_tfidf)\n",
    "q2_x = df2['question2'].apply(get_question_tfidf)\n",
    "print(time.clock()-start_time,\"seconds\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_list(series):\n",
    "    series_list=[]\n",
    "    for i in range(len(series)):\n",
    "        series_list.append(series[i])\n",
    "    return series_list\n",
    "\n",
    "\n",
    "def Make_columns(names,par):\n",
    "    columns_names = []\n",
    "    for i in range(1,names+1):\n",
    "        columns_names.append(str(i)+par)\n",
    "    return columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df1 = pd.DataFrame(data=Create_list(q1_x),columns=Make_columns(HEIGHEST_LEN,\"_x\"))\n",
    "temp_df2 = pd.DataFrame(data=Create_list(q2_x),columns=Make_columns(HEIGHEST_LEN,\"_y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df2,temp_df1,temp_df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 33)\n",
      "(100000, 253)\n",
      "(100000, 253)\n",
      "(100000, 539)\n"
     ]
    }
   ],
   "source": [
    "print(df2.shape)\n",
    "print(temp_df1.shape)\n",
    "print(temp_df2.shape)\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "# conn = sqlite3.connect(\"Any_Database_Name.db\")\n",
    "\n",
    "# final_df.to_sql('Some_Table_Name', conn)\n",
    "\n",
    "# sql_string = 'SELECT * FROM Some_Table_Name'\n",
    "# df33 = pd.read_sql(sql_string, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=final_df[\"is_duplicate\"]\n",
    "final_df.drop(columns=['question1','question2',\"is_duplicate\",\"qid1\",\"qid2\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv(r\"Z:\\DS DATA\\data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(\n",
    "    final_df, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (8000, 492)   X_train\n",
      "<class 'pandas.core.frame.DataFrame'> (2000, 492)   X_test\n",
      "<class 'pandas.core.series.Series'> (8000,)   y_train\n",
      "<class 'pandas.core.series.Series'> (2000,)   y_test\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),X_train.shape,\"  X_train\")\n",
    "print(type(X_test),X_test.shape,\"  X_test\")\n",
    "print(type(y_train),y_train.shape,\"  y_train\")\n",
    "print(type(y_test),y_test.shape,\"  y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Building a random model to calculate the worest-case of log_loss</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is line creates an ndarray of shape 3000x2 \n",
    "pred_y = np.zeros((len(y_test),2))\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "#     this is line will create a array 1X2 \n",
    "#     with random distribution populated in it\n",
    "    rand_probs = np.random.rand(1,2)\n",
    "    pred_y[i]= ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(log_loss(y_test,pred_y,eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.99200722162641e-16\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "predected = clf.predict(X_test)\n",
    "print(log_loss(y_test,predected,eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(list(y_test[:100]))\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE PDF DOWNLOADED\n",
    "\n",
    "# df_x = pd.read_csv(r\"Z:\\DS DATA\\train.csv\")\n",
    "\n",
    "# tfidfvectorizer_q1 = TfidfVectorizer()\n",
    "# q1_tfidf = tfidfvectorizer_q1.fit_transform(df_x[\"question1\"].values.astype(\"U\"))\n",
    "# q2_tfidf = tfidfvectorizer_q1.fit_transform(df_x[\"question2\"].values.astype(\"U\"))\n",
    "\n",
    "# from scipy.sparse import hstack\n",
    "# q1_q2 = hstack((q1_tfidf,q2_tfidf))\n",
    "\n",
    "# df_x1 = pd.read_csv(r\"Z:\\DS DATA\\feature_train.csv\")\n",
    "\n",
    "# df_x1.drop(columns=[\"id\",\"qid1\",\"qid2\",\"question1\",\"question2\"],inplace=True)\n",
    "\n",
    "# target = df_x1[\"is_duplicate\"]\n",
    "\n",
    "# df_tfidf = hstack((df_x1,q1_q2),format=\"csr\",dtype=\"float64\")\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train,X_test, y_train, y_test = train_test_split(\n",
    "#     df_tfidf, target, stratify=target, test_size=0.3)\n",
    "\n",
    "# print(type(X_train),X_train.shape,\"  X_train\")\n",
    "# print(type(X_test),X_test.shape,\"  X_test\")\n",
    "# print(type(y_train),y_train.shape,\"  y_train\")\n",
    "# print(type(y_test),y_test.shape,\"  y_test\")\n",
    "\n",
    "# clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "# predected = clf.predict(X_test)\n",
    "# print(log_loss(y_test,predected,eps=1e-15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
